{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "#import pandas as pd\n",
    "#import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = np.array([[2.0, 1.0, 1.0, 2.0],\n",
    "                 [-2.0, 1.0, -1.0, 2.0],\n",
    "                 [0.0, 1.0, 0.0, 2.0],\n",
    "                 [0.0, -1.0, 0.0, -2.0],\n",
    "                 [0.0, -1.0, 0.0, -2.0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  1.  1.  2.]\n",
      " [-2.  1. -1.  2.]\n",
      " [ 0.  1.  0.  2.]\n",
      " [ 0. -1.  0. -2.]\n",
      " [ 0. -1.  0. -2.]]\n"
     ]
    }
   ],
   "source": [
    "print(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.90119433  1.077483    0.93611842  2.00744729]\n",
      " [-2.0524804   1.0309404  -0.98402303  1.99709962]\n",
      " [-0.06262591  1.04401897 -0.01211146  2.00466849]\n",
      " [ 0.00999637 -1.0323493  -0.09783529 -1.93262067]\n",
      " [-0.01798234 -1.09395368 -0.05762689 -1.92439343]]\n"
     ]
    }
   ],
   "source": [
    "noisy_input = input + .2 *np.random.random_sample((input.shape)) - 0.1\n",
    "print(noisy_input)\n",
    "output = input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale to [0,1]\n",
    "scaled_input_1 = np.divide((noisy_input-noisy_input.min()), (noisy_input.max()-noisy_input.min()))\n",
    "scaled_output_1 = np.divide((output-output.min()), (output.max()-output.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale to [-1,1]\n",
    "scaled_input_2 = (scaled_input_1*2)-1\n",
    "scaled_output_2 = (scaled_output_1*2)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store training sets\n",
    "input_data = scaled_input_2\n",
    "output_data = scaled_output_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4)\n"
     ]
    }
   ],
   "source": [
    "# Autoencoder with 1 hidden layer\n",
    "n_samp, n_input = input_data.shape \n",
    "print(n_samp,n_input)\n",
    "n_hidden = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_3:0\", shape=(?, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Tanh_7:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Weights and biases to hidden layer\n",
    "Wh = tf.Variable(tf.random_uniform((n_input, n_hidden), -1.0 / math.sqrt(n_input), 1.0 / math.sqrt(n_input)))\n",
    "bh = tf.Variable(tf.zeros([n_hidden]))\n",
    "h = tf.nn.tanh(tf.matmul(x,Wh) + bh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights and biases to hidden layer\n",
    "Wo = tf.transpose(Wh) # tied weights\n",
    "bo = tf.Variable(tf.zeros([n_input]))\n",
    "y = tf.nn.tanh(tf.matmul(h,Wo) + bo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective functions\n",
    "y_ = tf.placeholder(\"float\", [None,n_input])\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "meansq = tf.reduce_mean(tf.square(y_-y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.05).minimize(meansq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/util/tf_should_use.py:189: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rounds = 5000\n",
    "batch_size = min(50, n_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 nan 0.36801025\n",
      "100 nan 0.10645832\n",
      "200 nan 0.027328763\n",
      "300 nan 0.026649421\n",
      "400 nan 0.013862586\n",
      "500 nan 0.004441638\n",
      "600 nan 0.002882983\n",
      "700 nan 0.0051319124\n",
      "800 nan 0.0029245946\n",
      "900 nan 0.0019264054\n",
      "1000 nan 0.002586922\n",
      "1100 nan 0.001584998\n",
      "1200 nan 0.0024677953\n",
      "1300 nan 0.0012799801\n",
      "1400 nan 0.0027117454\n",
      "1500 nan 0.0022246228\n",
      "1600 nan 0.0011955681\n",
      "1700 nan 0.0014487726\n",
      "1800 nan 0.002114424\n",
      "1900 nan 0.001456124\n",
      "2000 nan 0.0016458079\n",
      "2100 nan 0.0011438223\n",
      "2200 nan 0.0009471696\n",
      "2300 nan 0.0013445222\n",
      "2400 nan 0.0011536954\n",
      "2500 nan 0.0010306438\n",
      "2600 nan 0.001190569\n",
      "2700 nan 0.00068376365\n",
      "2800 nan 0.00094727165\n",
      "2900 nan 0.0009484558\n",
      "3000 nan 0.0010546943\n",
      "3100 nan 0.00088675617\n",
      "3200 nan 0.0011255072\n",
      "3300 nan 0.00047827425\n",
      "3400 nan 0.0005864988\n",
      "3500 nan 0.00045563263\n",
      "3600 nan 0.0003892884\n",
      "3700 nan 0.0010084948\n",
      "3800 nan 0.0006714685\n",
      "3900 nan 0.00074151997\n",
      "4000 nan 0.0005418913\n",
      "4100 nan 0.0005324886\n",
      "4200 nan 0.00066138816\n",
      "4300 nan 0.00073413807\n",
      "4400 nan 0.0008477947\n",
      "4500 nan 0.00031143095\n",
      "4600 nan 0.0005164363\n",
      "4700 nan 0.0005479726\n",
      "4800 nan 0.0004173525\n",
      "4900 nan 0.00072291406\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_rounds):\n",
    "    sample = np.random.randint(n_samp, size=batch_size)\n",
    "    batch_xs = input_data[sample][:]\n",
    "    batch_ys = output_data[sample][:]\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_:batch_ys})\n",
    "    if i % 100 == 0:\n",
    "        print i, sess.run(cross_entropy, feed_dict={x: batch_xs, y_:batch_ys}), sess.run(meansq, feed_dict={x: batch_xs, y_:batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      "[[ 1.   0.5  0.5  1. ]\n",
      " [-1.   0.5 -0.5  1. ]\n",
      " [ 0.   0.5  0.   1. ]\n",
      " [ 0.  -0.5  0.  -1. ]\n",
      " [ 0.  -0.5  0.  -1. ]]\n",
      "Final activations:\n",
      "[[ 9.5174634e-01  4.9805006e-01  5.0263149e-01  9.6193087e-01]\n",
      " [-9.4857842e-01  4.9820724e-01 -4.9902746e-01  9.8168182e-01]\n",
      " [ 2.1141766e-04  5.0387824e-01 -2.4395981e-03  9.7512311e-01]\n",
      " [ 1.2108896e-02 -5.0012153e-01  3.2923247e-03 -9.6374673e-01]\n",
      " [-1.0117810e-02 -5.0017446e-01 -3.3794809e-03 -9.6360588e-01]]\n",
      "Final weights (input => hidden layer)\n",
      "[[ 0.47246704  1.8769691 ]\n",
      " [ 0.5593799  -0.01597093]\n",
      " [ 0.14072388  0.563434  ]\n",
      " [ 2.071405   -0.24985194]]\n",
      "Final biases (input => hidden layer)\n",
      "[-0.09482063  0.2784614 ]\n",
      "Final biases (hidden layer => output)\n",
      "[-0.436461    0.00696699 -0.13244236  0.15712379]\n",
      "Final activations of hidden layer\n",
      "[[ 0.9925414   0.96832824]\n",
      " [ 0.9375245  -0.97171974]\n",
      " [ 0.9784151  -0.01363711]\n",
      " [-0.98086333  0.48588762]\n",
      " [-0.98132426  0.47416136]]\n"
     ]
    }
   ],
   "source": [
    "print \"Target:\"\n",
    "print output_data\n",
    "print \"Final activations:\"\n",
    "print sess.run(y, feed_dict={x: input_data})\n",
    "print \"Final weights (input => hidden layer)\"\n",
    "print sess.run(Wh)\n",
    "print \"Final biases (input => hidden layer)\"\n",
    "print sess.run(bh)\n",
    "print \"Final biases (hidden layer => output)\"\n",
    "print sess.run(bo)\n",
    "print \"Final activations of hidden layer\"\n",
    "print sess.run(h, feed_dict={x: input_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.50626448  0.56753969]\n",
      " [-0.38790239  0.94212781]\n",
      " [ 0.00510693 -0.65505028]\n",
      " ...\n",
      " [-0.22228562 -0.26590274]\n",
      " [-0.16290253 -0.671521  ]\n",
      " [ 0.57972669 -0.26283081]]\n"
     ]
    }
   ],
   "source": [
    "tot_number_samples = 10000\n",
    "X = np.random.uniform(-1,1,size=(tot_number_samples,2))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.50626448, -0.38790239,  0.00510693, ..., -0.22228562,\n",
       "       -0.16290253,  0.57972669])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (X[:,0] + X[:,1] >= 1).astype(np.double)*2-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function squeeze in module tensorflow.python.ops.array_ops:\n",
      "\n",
      "squeeze(*args, **kwargs)\n",
      "    Removes dimensions of size 1 from the shape of a tensor. (deprecated arguments)\n",
      "    \n",
      "    SOME ARGUMENTS ARE DEPRECATED. They will be removed in a future version.\n",
      "    Instructions for updating:\n",
      "    Use the `axis` argument instead\n",
      "    \n",
      "    Given a tensor `input`, this operation returns a tensor of the same type with\n",
      "    all dimensions of size 1 removed. If you don't want to remove all size 1\n",
      "    dimensions, you can remove specific size 1 dimensions by specifying\n",
      "    `axis`.\n",
      "    \n",
      "    For example:\n",
      "    \n",
      "    ```python\n",
      "    # 't' is a tensor of shape [1, 2, 1, 3, 1, 1]\n",
      "    tf.shape(tf.squeeze(t))  # [2, 3]\n",
      "    ```\n",
      "    \n",
      "    Or, to remove specific size 1 dimensions:\n",
      "    \n",
      "    ```python\n",
      "    # 't' is a tensor of shape [1, 2, 1, 3, 1, 1]\n",
      "    tf.shape(tf.squeeze(t, [2, 4]))  # [1, 2, 3, 1]\n",
      "    ```\n",
      "    \n",
      "    Args:\n",
      "      input: A `Tensor`. The `input` to squeeze.\n",
      "      axis: An optional list of `ints`. Defaults to `[]`.\n",
      "        If specified, only squeezes the dimensions listed. The dimension\n",
      "        index starts at 0. It is an error to squeeze a dimension that is not 1.\n",
      "        Must be in the range `[-rank(input), rank(input))`.\n",
      "      name: A name for the operation (optional).\n",
      "      squeeze_dims: Deprecated keyword argument that is now axis.\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor`. Has the same type as `input`.\n",
      "      Contains the same data as `input`, but has one or more dimensions of\n",
      "      size 1 removed.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: When both `squeeze_dims` and `axis` are specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help (tf.squeeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
